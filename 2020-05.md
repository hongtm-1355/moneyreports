# Ba Cách Lưu Trữ và Truy Cập Nhiều Hình Ảnh Trong Python

Lý do bạn muốn biết sự khác nhau giữ các cách lưu trữ và truy cập ảnh trong Python ? Nếu bạn phân chia các ảnh thành từng nhóm theo màu sắc hoặc nhanạ diện từng khuôn mặt bằng OpenCV, thì bạn không cần để tâm tới nó. Kể cả khi bạn sử dụng PIL để vẽ hàng trăm bức ảnh, bạn vẫn không cần biết cái này. Lưu trữ hình ảnh trên ổ đĩa thành file `.png` hay `.jpg` là quá đủ và phù hợp với nhu cầu của bạn.

Tuy nhiên, có nhiều vấn đề cẩn xử lý một khối lượng ảnh rất lớn, như trong vấn đề nhận diện hình ảnh, máy tính cần tập dữ liệu hình ảnh rất lớn, tới hàng ngàn, hàng triệu hỉnh ảnh.Nếu bạn chua biết thì [ImageNet](http://image-net.org/) là một cơ sở dữ liệu mở nơi chứa những tập dữ liệu phục vụ cho việc training model.

Quay lại vấn đề, nếu có tập ảnh lớn như vậy thì mất bao lâu để có thể load hết chúng vào bộ nhớ để training ? Khoan hãy trả lời, thay vào đó hãy cùng đi xem nội dung của bài viết này, bài viết sẽ dần dần trả lời cho bạn câu hỏi này. 

### Trong bài viết này, chúng ta sẽ tìm hiểu về:
- Lưu trữ hình ảnh dưới dạng `.png`
- Lưu trữ hình ảnh trong LMDB (lightning memory-mapped databases)
- Lưu trữ hình ảnh trong HDF5 (hierarchical data format)

### Bạn sẽ được khám về những điều sau:
- Tại sao phải cần phương thức lưu trức khác
- Sự khác nhau hiệu xuất khi bạn đọc/ ghi một ảnh
- Sự khác nhau về hiệu xuất khi bạn đọc/ghi nhiều ảnh 
- Làm thế nào để so sánh ba phương pháp trên

Nếu bạn không biết bất cứ phương pháp nào được đề cập trên kia thì cũng đừng quá lo lắng. Với bài viết này, tất cả những gì bạn cần là đã có nền tảng cơ bản về Python và hiểu về hỉnh ảnh là gì ở mức cơ bản. Nào hãy bắt đầu thôi !!!

## Chuẩn bị

Trước tiên, để tìm hiểu chúng ta cần một dataset ảnh dùng để thực hành, và một vài package cần thiết.

### Dataset

Chúng ta sẽ sử dụng bộ dữ liệu hình ảnh của Canadian Institute for Advanced Research được biết đến với tên là CIFAR-10 với 60,000 ảnh cỡ 32x32px thuộc nhiều thể loại khác nhau như chó, mèo, máy bay. CIFAR không phải tập dữ liệu quá lớn, nhưng nếu chúng ta sử dụng bộ dữ liệu khác như TinyImage, bạn sẽ cần tới 400GB hệ thống để lưu hết ảnh về, hơi mệt. 

Nếu bạn muốn thực hành theo các ví dụ trong bài viết này, bạn có thể download tập ảnh này ở [đây](https://www.cs.toronto.edu/~kriz/cifar.html).
![](https://files.realpython.com/media/cifar_10.e77ef0cd86df.png)

Khi bạn tải xuống và giải nén, bạn sẽ phát hiện rằng các tệp này không phải các tệp ảnh phổ thông mà chúng ta thường thấy. Chúng thực sự đã được serialized hóa và lưu thành từng batch bằng cPickle. Trong khi đó, `pickle` không phải nội dung của bài viết này, tuy nhiên phải nói là module này giúp chúng ta tuần tự xóa bất kỳ đối tượng Python nào mà không cần thêm bất kỳ mã hoặc chuyển đổi từ phía bạn.

Đoạn code bên dưới được sử dụng để gỡ 5 batch file và load tất cả ảnh vào Numpy array:

```python
import numpy as np
import pickle
from pathlib import Path

# Path to the unzipped CIFAR data
data_dir = Path("data/cifar-10-batches-py/")

# Unpickle function provided by the CIFAR hosts
def unpickle(file):
    with open(file, "rb") as fo:
        dict = pickle.load(fo, encoding="bytes")
    return dict

images, labels = [], []
for batch in data_dir.glob("data_batch_*"):
    batch_data = unpickle(batch)
    for i, flat_im in enumerate(batch_data[b"data"]):
        im_channels = []
        # Each image is flattened, with channels in order of R, G, B
        for j in range(3):
            im_channels.append(
                flat_im[j * 1024 : (j + 1) * 1024].reshape((32, 32))
            )
        # Reconstruct the original image
        images.append(np.dstack((im_channels)))
        # Save the label
        labels.append(batch_data[b"labels"][i])

print("Loaded CIFAR-10 training set:")
print(f" - np.shape(images)     {np.shape(images)}")
print(f" - np.shape(labels)     {np.shape(labels)}")
```

Tất cả ảnh giờ đã được load vào Ram trong biến `images` và ứng với nhãn của nó được lưu trong `labels`. Tiếp theo, ta hãy cài đặt các package cần thiết cho bài viết này.

### Thư viện thao tác với ảnh

Bạn sẽ cần thiết lập môi trường để có những phương thức cho việc lưu trữ và truy cập ảnh từ đổ địa. Bài viết này được viết trên môi trường Python 3.x, bạn sẽ sử dụng `Pillow` để thao tác với ảnh.

```shell=
pip install Pillow

```

### Thư viện LMDB

LMDB đôi khi được gọi là "Lightning Database", viết tắt của Lightning Memory-Mapped Database bởi vì nó nhanh và sử dụng memory-mapped filé. Nó lưu trữ theo dạng key-value, không phải một cơ sở dữ liệu quan hệ. LMDB có cấu trúc dạng B+ tree, cơ bản nó là cấu trúc dạng cây, được lưu trữ trong bộ nhớ trong đó môi cặp key-value là một nút, và các nút có thể có nhiều nhánh con. Các node cùng cấp được liên kết với nhau để duyệt nhanh hơn.

Quan trọng là, các thành phần chính của B+ Tree dược đặt để tương ứng với kích thước trang của hệ thống, tối đa hóa hiệu quả khi truy cập bất kỳ cặp key value nào trong cở sở dữ liệu. Một lý do quan trọng khác khiến LMDB hiệu quả là nó được ánh xạ bộ nhớ. Nghĩa là nó trả về con trỏ trực tiếp đến địa chỉ bộ nhớ của key và value, mà không cần sao chép bất cứ thứ gì trong bộ nhớ như hầu hết các cơ sở dữ liệu khác.

Để làm việc với LMDB, chúng ta dùng thư viện:

```shell=
pip install lmdb
```

### Thư viện để làm việc với HDF5

HDF5 viết tắ của Hierarchical Data Format, có định dạng file như HDF4 hoặc HDF5. Chúng ta không cần quan tâm tới HDF4, vì HDF5 là phiên bản đang được hỗ trợ ở thời điểm hiện tại. Điều thú vị là, HDF có nguồn gốc từ Nation Center for Supercomputing Apllication, là định dạng dữ liệu khoa học, nhỏ gọn. Nếu bạn đang tự hỏi nó được sử dụng rộng rãi hay không, hãy xem NASA giới thiệu về HDF5 từ dự án Dữ Liệu Trái đất của họ.

HDF chứa 2 kiểu object:
1. Datasets
2. Groups

Dataset là mảng đa chiều và groups chứa các dataset hoặc các group khác. MỖi dataset phải chứ một mảng n chiều đồng nhất. Bởi vì các nhóm và các bộ dữ liệu có thể được lồng vào nhau, tuy nhiên, điều này không bắt buộc. Để thao tác với H5 bạn cần cài đặt package sau:

```shell=
pip install h5py
```

## Lưu trữ một ảnh

Bây giờ bạn đã có một cái nhìn tổng qua về các phưng pháp, hãy cùng đi tìm hiểu và cùng so sánh chúng với một nhiệm vụ này : mất bao lâu để đọc, ghi tệp và bộ nhớ được sử dụng ra sao ? Điều này sẽ được giải thích thông qua việc tìm hiểu về cách các phương pháp hoạt động và các đoạn code ví dụ bên dưới. Khi tôi đề cập tới "files", tức là nó rất nhiều. Tuy nhiên, quan trọng là phải phân biệt vì một số phương pháp có thể được tối ưu hóa cho các hoạt động và số lượng tệp khác nhau.

Với mục đích thử nhiệm, chúng ta sẽ so sánh hiệu xuất giữa số lượng tập tin khác nhau, như các bội số của 10, từ 1 tới 100,000 ảnh. Tập ảnh của CIFAR-10 có 50k ảnh nên chúng ta sẽ sử dụng mỗi ảnh 2 lần để đạt được 100k ảnh.

Để chuẩn bị cho thử nghiệm, bạn sẽ cần tạo một thư mục cho mỗi phương pháp để chứ tất cả file cơ sở dữ liệu hoặc tập ảnh và lưu đường dẫn vào viến riêng.

```python=
from pathlib import Path

disk_dir = Path("data/disk/")
lmdb_dir = Path("data/lmdb/")
hdf5_dir = Path("data/hdf5/")
```

`Path` không tự động tạo thư mục cho tới khi bạn chỉ định nó:

```python=
disk_dir.mkdir(parents=True, exist_ok=True)
lmdb_dir.mkdir(parents=True, exist_ok=True)
hdf5_dir.mkdir(parents=True, exist_ok=True)
```

Bây giừ bạn có thể chuyển sang chạy các thử nghiệm với các code ví dụ. Chúng ta có thể dùng module `timeit` để giúp tính toán thời gian chạy.

### Lưu trữ trên ổ đĩa

Ở đây, input của ta sẽ là một ảnh, được lưu trong bộ nhớ dưới dạng mảng Numpy. Bạn muốn lưu nó trên ổ đĩa dưới dạng `.png` và với một tên duy nhất. Bạn có thể làm việc đó với Pillow

```python=
from PIL import Image
import csv

def store_single_disk(image, image_id, label):
    """ Stores a single image as a .png file on disk.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    Image.fromarray(image).save(disk_dir / f"{image_id}.png")

    with open(disk_dir / f"{image_id}.csv", "wt") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        writer.writerow([label])
```

Trong ứng dụng thực thế, bạn cũng quan tới dữ liệu meta được đính kèm trong ảnh, trong dataset ví dụ là nhãn của ảnh. Khi bạn lưu ảnh trên ổ địa, bạn có vài lựa hcọn để lưu metadata. Một trong số đó là mã hóa label thành tên của ảnh. Điều này sẽ không cần bất kỳ tập tin bổ sung nào. Tuy nhiên nó cũng có nhược điểm lớn là bạn sẽ phải xử lý vấn đề liên quan tới label khi bạn load ảnh. Lưu nhãn trong tệp riêng cho phép bạn thoải mái hơn. Ở dây, tôi sẽ lưu nó vào tệp `.csv`.

Bây giờ hãy chuyển sang LMDB nhen.

### Lưu trữ vào LMDB

Đầu tiên, LMDB là một hệ thống lưu trữ dạng key value, mỗi đối tượng dudơcj lưu dạng một mảng các byte, với key sẽ duy nhất cho mỗi ảnh, và giá trị là giá trị của ảnh. Cả key và value đều được mong muốn là dạng string, vì vayạ, cách sử dụng phổ biến là tuần tự hóa (serialize) giá trị thành dạng chuỗi và unserialize khi đọc nó.

Bạn có thể sử dụng `pickle` để làm điều này. Bất gì đối tượng Python nào cũng có thể được serialize, vì vậy bạn có thể gắn dữ liệu metadat trong cơ sở dữ liệu. Điều này giúp bạn tránh rắc rối khi gắn dữ liệu metadatâ trở lại hình ảnh khi chúng ta load dữ liệu.

Bạn có thể tạo một Class Python để lưu trữ ảnh và metadata:

```python=
class CIFAR_Image:
    def __init__(self, image, label):
        # Dimensions of image for reconstruction - not really necessary 
        # for this dataset, but some datasets may include images of 
        # varying sizes
        self.channels = image.shape[2]
        self.size = image.shape[:2]

        self.image = image.tobytes()
        self.label = label

    def get_image(self):
        """ Returns the image as a numpy array. """
        image = np.frombuffer(self.image, dtype=np.uint8)
        return image.reshape(*self.size, self.channels)
```

Tiếp theo, bởi vì LMDB là memory-mapped, một database mới cần biết số lượng bộ nhớ cần để sử dụng tới. Điều này tương đối đơn giản, nhưng nó có thể trở thành nỗi đau đớn ở trường hợp khác mà bạn sẽ thấy ở phần sau. LMDB gọi biến này là `map_size`.

Cuối cùng, đọc và ghi với LMDB được xử lý qua `transaction`. Bạn có thể nghĩ nó như cơ sở dữ liệu truyền thống, bao gồm các nhóm hoạt động trên cơ sở dữ liệu. Điều này trông phức tạp hơn đáng để so với phiên bản lưu trữ trên ổ đĩa, nhưng hay tiếp tục nào.

Với ba điểm này trong tâm trí, chúng ta hãy xem xét code bên dưới nhes:


```python=
import lmdb
import pickle

def store_single_lmdb(image, image_id, label):
    """ Stores a single image to a LMDB.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    map_size = image.nbytes * 10

    # Create a new LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), map_size=map_size)

    # Start a new write transaction
    with env.begin(write=True) as txn:
        # All key-value pairs need to be strings
        value = CIFAR_Image(image, label)
        key = f"{image_id:08}"
        txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()
```

### Lưu trữ với HDF5

Nhớ là HDF5 có thể chứa nhiều hơn một dataset.  Trong trường hợp nhỏ này, bạn có thể tạo hai tập dataset, một cho ảnh, một cho metadata:

```python=
import h5py

def store_single_hdf5(image, image_id, label):
    """ Stores a single image to an HDF5 file.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "image", np.shape(image), h5py.h5t.STD_U8BE, data=image
    )
    meta_set = file.create_dataset(
        "meta", np.shape(label), h5py.h5t.STD_U8BE, data=label
    )
    file.close()
```

`h5py.h5t.STD_U8BE` chỉ định kiểu dữ liệu mà dataset sẽ lưu, trong trường hợp này là unsigned 8-bit integers. Bạn có thể xem danh sách đầy đủ ở [đây](http://api.h5py.org/h5t.html).


### Thí nghiệm về việc lưu trữ một ảnh

Bây giờ bạn có thể đặt 3 hàm kia vào một dictionày, rồi gọi nó để tính thời gian thí nghiệm.

```python=
_store_single_funcs = dict(
    disk=store_single_disk, lmdb=store_single_lmdb, hdf5=store_single_hdf5
)
```

Cuối cùng, hãy thử nghiệm với chúng để thấy sự khác nhau.

```python=
from timeit import timeit

store_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_store_single_funcs[method](image, 0, label)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    store_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```
> Chú ý là LMDB không ghi đè giá trị lên key có sẵn, nên bạn sẽ gặp lỗi `MapFullError: mdb_txn_commit: MDB_MAP_FULL: Environment mapsize limit reached` nếu bạn cố tình làm vậy. Hãy đảm bảo xóa hết dữ liệu khi bạn thực hành nhiều lần.

Hãy nhớ rằng chúng tôi rất quan tâm đến thời gian chạy, được hiển thị ở đây trong vài giây và cả việc sử dụng bộ nhớ:


| Method | Save Single Image + Meta | Memory |
| -------- | -------- | -------- |
| Disk     | 1.915 ms     | 8 K     |
| LMDB     | 1.203 ms     | 32 K     |
| HDF5     | 8.243 ms     | 8 K     |

Có 2 điều rút ra từ bảng nayf:
1. Tất cả đều thực hiện khá nhanh
2. LMDB sử dụng tài nguyên nhiều hơn.

Rõ ràng, mặc dù LMDB có một hiệu suất dẫn đầu về tốc độ, tuy nhiên chúng tôi không cố thuyết phục bấy kỳ ai lý do tại sao không lưu ảnh trên ổ địa. Sau cùng, nó là một định dạng dễ đọc cho con người, có thể mở bằng bấy kỳ trình duyệt nào. Bây giờ, đã tới lúc dùng nhiều hình ảnh hơn rồi.

## Lưu trữ nhiều ảnh

Bạn đã có code để lưu trữ một ảnh, bây giờ chúng ta cần điều chỉnh để lưu nhiều ảnh và chạy thí nghiệm

### Điều chỉnh code với nhiều ảnh

Lưu nhiều ảnh dưới dạng `.png` chỉ đơn giản là gọi `store_single_method()` nhiều lần. Nhưng với LMDB và HDF5 thì không hoàn toàn đúng, vì bạn không muốn có một có một database khác nhau cho mỗi ảnh. Thay vào đó, bạn muốn đặt tất cả ảnh vào một hoặc nhiều file. Bạn sẽ cần sửa lại code và tạo 3 hàm mới cho phép xử lý nhiều ảnh `store_many_disk()`, `store_many_lmdb()`, `and store_many_hdf5`:

```python=
store_many_disk(images, labels):
    """ Stores an array of images to disk
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Save all the images one by one
    for i, image in enumerate(images):
        Image.fromarray(image).save(disk_dir / f"{i}.png")

    # Save all the labels to the csv file
    with open(disk_dir / f"{num_images}.csv", "w") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for label in labels:
            # This typically would be more than just one value per row
            writer.writerow([label])

def store_many_lmdb(images, labels):
    """ Stores an array of images to LMDB.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    map_size = num_images * images[0].nbytes * 10

    # Create a new LMDB DB for all the images
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), map_size=map_size)

    # Same as before — but let's write all the images in a single transaction
    with env.begin(write=True) as txn:
        for i in range(num_images):
            # All key-value pairs need to be Strings
            value = CIFAR_Image(images[i], labels[i])
            key = f"{i:08}"
            txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()

def store_many_hdf5(images, labels):
    """ Stores an array of images to HDF5.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "images", np.shape(images), h5py.h5t.STD_U8BE, data=images
    )
    meta_set = file.create_dataset(
        "meta", np.shape(labels), h5py.h5t.STD_U8BE, data=labels
    )
    file.close()
```

Vì vậy, bạn có thể lưu trữ nhiều hơn một tệp vào ổ địa, các phương pháp đã được thay đổi để lập qua mỗi ảnh trong danh sách. Với LMDB, một vòng lặp sẽ tạo một đối tượng CIFAR_Image cho mỗi hình ảnh và metadata của nó.

Thay đổi nhỏ với HDF5, HDF5 không giới hạn về kích thước tệp , vì vayạ tất cả hình ảnh được nhồi vào một file duy nhất giống như trước đây. Tiếp theo, bạn sẽ  cần chuẩn bị một tập dataset để thực hienẹ thí nghiệm.

### Chuẩn bị dataset

Trước khi chạy thí nghiệm, hãy nhân đôi kích thước dataset của ta thành nhiều tập tối đa là 100k ảnh.

```python=
cutoffs = [10, 100, 1000, 10000, 100000]

# Let's double our images so that we have 100,000
images = np.concatenate((images, images), axis=0)
labels = np.concatenate((labels, labels), axis=0)

# Make sure you actually have 100,000 images and labels
print(np.shape(images))
print(np.shape(labels))
```

Giờ, đã đủ để thí nghiệm rùi

### Thử nghiệm lưu nhiều ảnh

Như bạn đã làm việc với việc đọc ảnh, bạn có thể tạo một dictionảy để xử lý tất cả chức năng với `store_many_` và chạy thử nhieemj:

```python=
_store_many_funcs = dict(
    disk=store_many_disk, lmdb=store_many_lmdb, hdf5=store_many_hdf5
)

from timeit import timeit

store_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_store_many_funcs[method](images_, labels_)",
            setup="images_=images[:cutoff]; labels_=labels[:cutoff]",
            number=1,
            globals=globals(),
        )
        store_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, Time usage: {t}")
```

Hãy chạy đoạn code, bạn sẽ cần chờ đợi ít phút để 111,110 ảnh được lưu trữ 3 lần vào ổ đĩa, với ba phương thức khác nhau. Sau thời gian chờ đợi, bạn sẽ nhận được kết quả như hình.

![](https://files.realpython.com/media/store_many.273573157770.png)
![](https://files.realpython.com/media/store_many_log.29e8ae980ab6.png)

Biểu đồ đầu tiên cho thấy thời gian lưu trữ bình thường, chưa được điều chỉnh làm nổi bật sự khác biệt giữa ba phương pháp.

Biểu đồ thứ hai hiện thêm nhật lý thời gian, làm nổi bật HDF5 chậm hơn LMDB

Trong khi kết quả chính xác phụ thuộc vào máy của bạn, nên đay là lý do để LMDB và HDF5 đáng để suy nghĩ. Đây là mã tạo biểu đồ:

```python=
import matplotlib.pyplot as plt

def plot_with_legend(
    x_range, y_data, legend_labels, x_label, y_label, title, log=False
):
    """ Displays a single plot with multiple datasets and matching legends.
        Parameters:
        --------------
        x_range         list of lists containing x data
        y_data          list of lists containing y values
        legend_labels   list of string legend labels
        x_label         x axis label
        y_label         y axis label
    """
    plt.style.use("seaborn-whitegrid")
    plt.figure(figsize=(10, 7))

    if len(y_data) != len(legend_labels):
        raise TypeError(
            "Error: number of data sets does not match number of labels."
        )

    all_plots = []
    for data, label in zip(y_data, legend_labels):
        if log:
            temp, = plt.loglog(x_range, data, label=label)
        else:
            temp, = plt.plot(x_range, data, label=label)
        all_plots.append(temp)

    plt.title(title)
    plt.xlabel(x_label)
    plt.ylabel(y_label)
    plt.legend(handles=all_plots)
    plt.show()

# Getting the store timings data to display
disk_x = store_many_timings["disk"]
lmdb_x = store_many_timings["lmdb"]
hdf5_x = store_many_timings["hdf5"]

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Storage time",
    log=False,
)

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Log storage time",
    log=True,
)
```

## Đọc một ảnh đơn

Đầu tiên, hãy xem xét trường hợp đọc một ảnh thành một mảng bằng ba phương pháp này.

### Đọc từ ổ đĩa

Trong ba phương pháp, LMDB yêu cầu đòi hỏi nhiều công nhất khi đọc tệp hình ảnh từ bồ nhớ, vì nó có bước serialization. Bây giờ hãy cùng xem qua các chức năng để đọc một hình ảnh cho mỗi phương pháp lưu trữ.

Đầu tiên, đọc dữ liệu ảnh và meta của nó từ `.png` hoặc `.csv`:

```python=
def read_single_disk(image_id):
    """ Stores a single image to disk.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    image = np.array(Image.open(disk_dir / f"{image_id}.png"))

    with open(disk_dir / f"{image_id}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        label = int(next(reader)[0])

    return image, label
```

### Đọc Từ LMDB

Tiếp theo, làm tương tự khi đọc từ LMDB:

```python=
def read_single_lmdb(image_id):
    """ Stores a single image to LMDB.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Encode the key the same way as we stored it
        data = txn.get(f"{image_id:08}".encode("ascii"))
        # Remember it's a CIFAR_Image object that is loaded
        cifar_image = pickle.loads(data)
        # Retrieve the relevant bits
        image = cifar_image.get_image()
        label = cifar_image.label
    env.close()

    return image, label
```

Ở đây chúng ta có hai điểm cần giải thích:
- Dòng 13: `readonly=True` chỉ định rằng không cho phép ghi tệp LMDB cho đến khi kết trúc tracsaction. Trong CSDL, nó đương đương với từ khóa `lock`.
- Dòng 20: Để truy xuất đối tượng `CIFAR_Image`, bạn cần đảo ngược lại bước mà chúng ta thực hiện khi ghi nó.

### Đọc từ HDF5

Đọc từ HDF5 cũng tương tự như quá trình ghi. 

```python
def read_single_hdf5(image_id):
    """ Stores a single image to HDF5.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "r+")

    image = np.array(file["/image"]).astype("uint8")
    label = int(np.array(file["/meta"]).astype("uint8"))

    return image, label
```

Chú ý rằng, bạn truy cập tới dataset khác nhau bằng cách đánh index đối tượng bằng các sử dụng tên cho các tập dataset đứng trươc dấu `/`. Như trước đay, bạn có thể tạo một diction nary chứa các hàm ddocj:

```python=
_read_single_funcs = dict(
    disk=read_single_disk, lmdb=read_single_lmdb, hdf5=read_single_hdf5
)
```

### Thử nghiệm đọc ảnh đơn

Bạn có thể kì vọng thằng thử nghiểm với ảnh đơn sẽ cho kết quả bình thường.

```python=

read_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_read_single_funcs[method](0)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    read_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```

Và đây là kết quả



| Method | Reading single image + meta | 
| -------- | -------- | 
| Disk     | 1.61970 ms     | 
| LMDB     | 4.52063 ms     |
| HDF5     | 1.98036 ms     |

NKết quả đọc từ ổ đĩa có nhanh hơn, nhưng nhìn chung cả 3 phương pháp đều nhanh chóng.

## Đọc nhiều ảnh

Bây giờ bạn có thể điểu chỉnh code của bạn để đọc nhiều ảnh.

### Điều chỉnh code để đọc nhiều ảnh hơn

Kế thừa từ các hàm trước, bạn có thể tạo ra một hàm `with_many_`, có thể được sử dụng cho các thí nghiệm tiếp theo. 

```python=
def read_many_disk(num_images):
    """ Reads image from disk.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Loop over all IDs and read each image in one by one
    for image_id in range(num_images):
        images.append(np.array(Image.open(disk_dir / f"{image_id}.png")))

    with open(disk_dir / f"{num_images}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for row in reader:
            labels.append(int(row[0]))
    return images, labels

def read_many_lmdb(num_images):
    """ Reads image from LMDB.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Read all images in one single transaction, with one lock
        # We could split this up into multiple transactions if needed
        for image_id in range(num_images):
            data = txn.get(f"{image_id:08}".encode("ascii"))
            # Remember that it's a CIFAR_Image object 
            # that is stored as the value
            cifar_image = pickle.loads(data)
            # Retrieve the relevant bits
            images.append(cifar_image.get_image())
            labels.append(cifar_image.label)
    env.close()
    return images, labels

def read_many_hdf5(num_images):
    """ Reads image from HDF5.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "r+")

    images = np.array(file["/images"]).astype("uint8")
    labels = np.array(file["/meta"]).astype("uint8")

    return images, labels

_read_many_funcs = dict(
    disk=read_many_disk, lmdb=read_many_lmdb, hdf5=read_many_hdf5
)
```

### Thử nghiệm

```python=
from timeit import timeit

read_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_read_many_funcs[method](num_images)",
            setup="num_images=cutoff",
            number=1,
            globals=globals(),
        )
        read_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, No. images: {cutoff}, Time usage: {t}")
```

Như chúng ta đã làm trước đây, chúng ta có thể vẽ biểu đồ kết quả thử nghiệm đã đọc.

![](https://files.realpython.com/media/read_many.9c4a6dc5bdc0.png)

![](https://files.realpython.com/media/read_many_log.594dac8746ad.png)

Biểu đồ trên cùng cho thấy thời gian đọc bình thường, k điều chỉnh cho thấy sự khác biệt lớn giữa các phương pháp. Ngược lại biểu đố dưới là log time, làm nổi bật nên sự khác biệt. Như t thấy HDF5 nhanh hơn LMDB.


Trong thục tế, thời gian ghi thường ít quan trọng hơn thời gian độc. Hãy tưởng tượng rằng bạn training một DNN trên nhiều ảnh và chỉ một nửa tập dữ liệu ảnh dùng RAM cùng lcú. Mỗi chu kỳ đào tạo yêu cầu một tập dataset , và model cần vài trăm chu kỳ để hội tụ. Bạn sẽ đọc một nửa giữ liệu vào ram mỗi chu kỳ.

Có một số thủ thuật mọi người hay làm, chẳng hạn như training pseudo-epoch để làm điều đó tốt hơn.

Bây giờ hãy nhìn biểu đồ bên dưới. Tự khác nhau giữa 40s và 3s đọc nó sẽ tươn đương với 6h để training hoặc 40p

![](https://files.realpython.com/media/read_write.a4f87d39489d.png)

## Xem xét tài nguyên ổ cứng được sử dụng

Tốc độ không phải là chỉ số hiệu suất duy nhất mà bạn có thể quan tâm. Chúng ta đã xử lý nhiều tập dataset lớn, nên không gian lưu trữ cũng là một thứ đang để quan tâm.

Giả sử bạn có một tập dataset là 3TB. Vậy số dung lượng mà mỗi phương thức sử dụng là bao nhiêu. Đây là thông tin cho việc đó

![](https://files.realpython.com/media/store_mem.dadff24e67e3.png)

```python=
# Memory used in KB
disk_mem = [24, 204, 2004, 20032, 200296]
lmdb_mem = [60, 420, 4000, 39000, 393000]
hdf5_mem = [36, 304, 2900, 29000, 293000]

X = [disk_mem, lmdb_mem, hdf5_mem]

ind = np.arange(3)
width = 0.35

plt.subplots(figsize=(8, 10))
plots = [plt.bar(ind, [row[0] for row in X], width)]
for i in range(1, len(cutoffs)):
    plots.append(
        plt.bar(
            ind, [row[i] for row in X], width, bottom=[row[i - 1] for row in X]
        )
    )

plt.ylabel("Memory in KB")
plt.title("Disk memory used by method")
plt.xticks(ind, ("PNG", "LMDB", "HDF5"))
plt.yticks(np.arange(0, 400000, 100000))

plt.legend(
    [plot[0] for plot in plots], ("10", "100", "1,000", "10,000", "100,000")
)
plt.show()
```

Cả HDF5 và LMDB điều chiếm nhiều dung lượng hơn so với lưu ảnh `.png` thông thường. Điêu quan trọng cần lưu ý là cả hiệu suất cảu LMDB và HDF5 phụ thuộc vào yếu tố khác nhau, bao gồm hệ điều hành, kích thức của dữ liệu.

LMDB cho phép đạt được hiệu quả từu bộ đệm và tận dụng các kích thước trang của OS. Bạn không cần hiểu nó hoạt động như nào, nhưng chú ý răng ảnh lớn sẽ dùng nhiều dung lượn hơn, bởi ảnh không được đặt trong page của LMDB, thay vào đó bạn sẽ có nhiều page tràn. 

Mặc dù không thí nghiệm, nhưng theo kinh nghiệm của tcs giả, hình ảnh 256x256x3 và 512x512x3, HDF5 thường cho hiệu quả tốt hơn các phương pháp khác.

## Tổng kết

Trong bài viết này, bạn đã được giới thiệu 3 cách để lưu và truy cập ảnh trong Python. Bạn đã thấy bằng chứng về cách các phương thức lưu trữ khác nhau có thể ảnh hưởng mạnh đến thời gian đọc và viết, cũng như một vài ưu và nhược điểm của ba phương pháp được xem xét trong bài viết này. Mặc dù lưu trữ hình ảnh dưới dạng tệp .png có thể trực quan nhất, có những lợi ích hiệu suất lớn để xem xét các phương pháp như HDF5 hoặc LMDB.

































